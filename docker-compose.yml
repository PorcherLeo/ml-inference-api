services:
  api:
    build: .
    ports:
      - "8000:8000"            # change en "8001:8000" si 8000 est occupé
    volumes:
      - ./models:/app/models   # modèle local
      - ./mlruns:/app/mlruns   # logs MLflow si tu loggues depuis le conteneur
    environment:
      - MLFLOW_TRACKING_URI=file:/app/mlruns

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    command: mlflow ui --host 0.0.0.0 --port 5000 --backend-store-uri file:/mlruns
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlruns
